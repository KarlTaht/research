# Configuration for CustomTransformer on tiny-textbooks

model:
  d_model: 256
  n_blocks: 4
  n_heads: 4
  d_ffn: 512
  max_seq_len: 256

data:
  dataset: "nampdn-ai/tiny-textbooks"
  text_column: "textbook"
  max_length: 256
  use_subset: true
  subset_size: 5000

training:
  batch_size: 8
  learning_rate: 0.001
  num_epochs: 5
  eval_every: 500       # Steps between evaluations
  save_every: 1         # Epochs between checkpoints
  log_every: 100        # Steps between loss logging
