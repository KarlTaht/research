# Training config for automotive corpus
# Target: ~25-30M parameters, 1024 context length

experiment_name: "automotive_baseline"

model:
  d_model: 384
  n_blocks: 6
  n_heads: 6        # d_head = 64
  d_ffn: 1536       # 4x d_model
  max_seq_len: 1024
  dtype: bfloat16

data:
  corpus_dir: "data/corpus_automotive"
  tokenizer: "combined_bpe_32768"
  max_length: 1024
  subset_size: 10000  # Uncomment for quick tests

training:
  batch_size: 12
  learning_rate: 0.0003
  min_learning_rate: 0.00003
  lr_decay: cosine
  warmup_ratio: 0.05
  weight_decay: 0.01
  num_epochs: 3

  log_every: 100
  eval_every: 500
  save_every: 1
  checkpoint_interval_minutes: 15  # Time-based checkpoints

  max_grad_norm: 1.0

evaluation:
  generation_prompts:
    - "The engine"
    - "When you drive"
    - "The best way to"
  max_generation_length: 100
  temperature: 0.8
  top_k: 50
