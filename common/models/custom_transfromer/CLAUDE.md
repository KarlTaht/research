# CustomTransformer

## Purpose
This is an **educational, low-level implementation** of a decoder-only transformer.

## Design Philosophy
- **Depth of understanding over efficiency** — code prioritizes clarity and learning
- **Pure tensor operations** — minimal use of high-level PyTorch modules
- **Explicit over implicit** — operations are spelled out rather than abstracted

## Guidance for AI Assistants
When providing advice on this codebase:
- Do NOT optimize for performance or production-readiness
- DO explain the "why" behind each operation
- DO use concrete examples with small dimensions
- DO relate new concepts to existing code patterns (e.g., the FCNN)
- Keep explanations concise and conversational
